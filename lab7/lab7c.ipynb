{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 7 Classifier Tools\n",
    "\n",
    "<hr>\n",
    "\n",
    "### 1. VisionX documentation reminder\n",
    "\n",
    "1. The traditional method to obtain documentation about a linux command is \"man <command-name>\" this also works for VisionX commands\n",
    "2. The method to gain information about anything is to google. Thus, to gain information about anything including command documentation consider using a google search on \"visionx v4 <anything>\" Example: \"visionx v4 multichannel\" and ignore the Ads.\n",
    "\n",
    "<hr>\n",
    "    \n",
    "### 2. bash scripts for processing a set of files\n",
    "\n",
    "Example: to convert a set of files in VisionX format with a  .vx extension to png format files with the same rootname and a .png extension:\n",
    "```sh\n",
    "#!/bin/sh\n",
    "for i in *.vx\n",
    "do\n",
    "  root=`echo $i| sed -e 's/\\(.*\\)\\..*/\\1/'`\n",
    "  echo vxport  -png if=$i of=$root.png\n",
    "done\n",
    "```\n",
    "Given a directory with the files im1.vx and im2.vx the above script generated the following:\n",
    "```sh\n",
    "vxport -png if=im1.vx of=im1.png\n",
    "vxport -png if=im2.vx of=im2.png\n",
    "```\n",
    "To make the script execute rather than just print the above commands remove the word \"echo\" (bash print command) from the script.\n",
    "<p>\n",
    "\n",
    "To be a little more fancy if you have already created a .csv file \"labels.csv\" with the content:\n",
    "```\n",
    "tst0.png,7\n",
    "tst1.png,2\n",
    "```\n",
    "then consider the script:\n",
    "```sh\n",
    "  #!/bin/sh\n",
    "  for i in $(cut -d, -f1 labels.csv)\n",
    "  do\n",
    "    root=`echo $i| sed -e 's/\\(.*\\)\\..*/\\1/'`\n",
    "    echo vxport  -png if=$root.vx  of=$root.png\n",
    "  done\n",
    "```\n",
    "Which produces the output:\n",
    "```sh\n",
    "vxport -png if=tst0.vx of=tst0.png\n",
    "vxport -png if=tst1.vx of=tst1.png\n",
    "```\n",
    "\n",
    "OF course equivalent scripts may be written in python if you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Print the times for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "#Train the classifier\n",
    "KNN.fit(X,y)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 3NN is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Example Classifier parameters that can be used with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "### Nearest Neighbor Classifier\n",
    "#\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "#\n",
    "###  Multi-layer perceptron\n",
    "#\n",
    "# Single hidden layer\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "# Note, the iteration limit will be reached! \n",
    "#\n",
    "# Two hidden layers\n",
    "mlp_2 = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "#\n",
    "### Support Vector Machines\n",
    "##\n",
    "## Linear\n",
    "clf = SVC(kernel = 'linear', C = 1)\n",
    "##\n",
    "## cubic polynomial\n",
    "clf = SVC(kernel = 'poly',degree = 3, C = 1)\n",
    "##\n",
    "## Radial basis functions\n",
    "clf = SVC(kernel = 'rbf', C = 1, gamma = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Principle Component Analysis (PCA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Apply PCA after data splitting and standardization.\n",
    "#Wisely choose the number of components (n_components) or the amount of variance retained. \n",
    "pca = PCA(n_components=<value>)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. K- Nearest Neighbor Visualization of Decision Boundary\n",
    "The following elegant code will show the decision boundary in a two-dimensional graph for\n",
    "two features. Unfortunately, many more features are required for lab 7 MNIST so\n",
    "it is not sutable for that task. The visualization problem for mutiple dimensions\n",
    "remians and unsolved task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap_light = ListedColormap(['orange', 'c', 'cornflowerblue','b','r',\n",
    "                             'g','m','y','w','lightsalmon'])\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "X_train1 = X_train[:200, :2] #Visualizing 2 features of first 200 images\n",
    "y_train1 = y_train[:200]\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train1, y_train1)\n",
    "\n",
    "x_min, x_max = X_train1[:, 0].min() - 1, X_train1[:, 0].max() + 1\n",
    "y_min, y_max = X_train1[:, 1].min() - 1, X_train1[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = KNN.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z1, cmap=cmap_light);\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train1[:, 0], X_train1[:, 1], c=y_train1, cmap=cmap_light,\n",
    "            edgecolor='k', s=20);\n",
    "plt.xlim(xx.min(), xx.max());\n",
    "plt.ylim(yy.min(), yy.max());\n",
    "plt.title(\"10-Class classification (k = 3)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
